<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>VoiceGPT</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-4bw+/aepP/YC94hEpVNVgiZdgIC5+VKNBQNGCHeKRQN+PtmoHDEXuppvnDJzQIu9" crossorigin="anonymous">
    <style>
        body {
            background-color: dimgray;
            color: white;
            margin-top: 10px;
        }

        h1 {
            text-align: center;
            color: white;
        }

        #result {
            text-align: center;
            white-space: nowrap;
            overflow: hidden;
            font-size: 24px;
        }
        #result2 {
            text-align: center;
            margin-top: 10px;
            white-space: nowrap;
            overflow: hidden;
            font-size: 24px;
        }
    </style>
</head>
<body>
    <div class="container-fluid">
        <h1>VoiceGPT</h1>
        <div class="row">
            <button class="btn btn-success" id="recordButton">Start Recording</button>
        </div>
        <div class="row"><p class="text-wrap" id="result"></p></div>
        <div class="row"><p class="text-wrap" id="result2"></p></div>
    </div>

    <script>
        const recordButton = document.getElementById("recordButton");
        const resultDiv = document.getElementById("result");
        const resultDiv2 = document.getElementById("result2");

        let recognizing = false;
        let finalTranscript = '';
        let silenceTimer;

        let recognition;

        function setupRecognition() {
            recognition = new webkitSpeechRecognition() || speechRecognition();
            recognition.continuous = true;
            recognition.interimResults = true;
            recognition.lang = "de-DE"; // You can change the language as needed

            recognition.onstart = () => {
                recognizing = true;
                recordButton.className = "btn btn-danger";
                recordButton.textContent = "Stop Recording";
            };

            recognition.onend = () => {
                recognizing = false;
                recognition.stop();
                // After recording, send the recorded text for translation
                getOpenAIResponse(document.getElementById("result").innerHTML)
                    .then(translatedText => {
                        if (translatedText) {
                            // Play the translated text to the user's speakers
                            return playText(translatedText);
                        }
                    })
                    .catch(error => {
                        console.error('Error getting translation:', error);
                    });
                recordButton.className = "btn btn-success";
                recordButton.textContent = "Start Recording";
            };

            recognition.onresult = event => {
                const lastResult = event.results[event.results.length - 1];

                let interimTranscript = '';
                for (let i = event.resultIndex; i < event.results.length; i++) {
                    const transcript = event.results[i][0].transcript;
                    if (!lastResult.isFinal) {
                        interimTranscript += transcript + ' ';
                    } else {
                        finalTranscript += transcript + ' ';
                    }
                }

                resultDiv.innerHTML = finalTranscript + interimTranscript;

                const silenceThreshold = 1000; // Adjust as needed (in milliseconds)

                if (!lastResult.isFinal) {
                    if (silenceTimer) {
                        clearTimeout(silenceTimer);
                    }

                    silenceTimer = setTimeout(() => {
                        if (recognizing) {
                            recognition.stop();
                            // After recording, send the recorded text for translation
                            getOpenAIResponse(document.getElementById("result").innerHTML)
                                .then(translatedText => {
                                    if (translatedText) {
                                        // Play the translated text to the user's speakers
                                        return playText(translatedText);
                                    }
                                })
                                .catch(error => {
                                    console.error('Error getting translation:', error);
                                });
                        }
                    }, silenceThreshold);
                } else {
                    if (silenceTimer) {
                        clearTimeout(silenceTimer);
                    }
                }
            };
        }

        setupRecognition();

        async function toggleRecording() {
            if (recognizing) {
                recognition.stop();
                recognizing = false;
                return; // Do not continue if already recognizing
            }

            finalTranscript = '';
            resultDiv.innerHTML = '';
            resultDiv2.innerHTML = '';

            setupRecognition(); // Set up a new recognition instance
            recognition.start();
        }

        async function getOpenAIResponse(prompt) {
            const body = {
                model: "gpt-3.5-turbo",
                max_tokens: 4000,
                messages: [
                    { role: "system", content: "" },
                    { role: "user", content: prompt },
                ],
            };
            const headers = {
                "Content-Type": "application/json",
                "api-key": "eca0d85b7f0a4d688a92262ef6f34864",
            };
            const url = "https://cog-fmmdzwfew525e.openai.azure.com/openai/deployments/chat/chat/completions?api-version=2023-03-15-preview";

            try {
                const response = await fetch(url, {
                    method: "POST",
                    headers: headers,
                    body: JSON.stringify(body),
                });

                if (!response.ok) {
                    throw new Error('Network response was not ok');
                }

                const data = await response.json();
                const text = data.choices[0].message.content;
                console.log(`Azure OpenAI response to Prompt (${prompt}): ${text}`);
                resultDiv2.innerHTML = text;
                return text;
            } catch (error) {
                console.error('API Error:', error);
                return null;
            }
        }

        function playText(text) {
            return new Promise((resolve) => {
                const synth = window.speechSynthesis;
                const utterance = new SpeechSynthesisUtterance(text);
                utterance.lang = 'de-DE'; // Set the language for text-to-speech output to German

                utterance.onend = () => {
                    resolve(); // Resolve the promise after playback
                };

                synth.speak(utterance);
            });
        }

        recordButton.addEventListener("click", toggleRecording);
    </script>
</body>
</html>
